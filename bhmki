import os
import cv2
import io
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from skimage.filters import threshold_sauvola
from deskew import determine_skew
import fitz  # PyMuPDF
import concurrent.futures
import torch
from transformers import DetrImageProcessor, DetrForObjectDetection

class PreprocessAgent:
    def __init__(self):
        self.layout_processor = DetrImageProcessor.from_pretrained("cmarkea/detr-layout-detection")
        self.layout_model = DetrForObjectDetection.from_pretrained("cmarkea/detr-layout-detection")
        try:
            self.font = ImageFont.truetype("arial.ttf", 24)
        except:
            self.font = ImageFont.load_default()

    def normalize_document(self, input_path):
        ext = os.path.splitext(input_path)[1].lower()
        handlers = {
            '.pdf': self._handle_pdf,
            '.txt': self._handle_txt,
            '.docx': self._handle_docx,
            '.jpg': self._handle_image,
            '.jpeg': self._handle_image,
            '.png': self._handle_image,
            '.bmp': self._handle_image,
            '.tiff': self._handle_image
        }
        if ext in handlers:
            return handlers[ext](input_path)
        raise ValueError(f"Unsupported file type: {ext}")

    def _handle_pdf(self, path):
        doc = fitz.open(path)
        return [{'image': Image.frombytes("RGB", [p.get_pixmap(dpi=300).width, p.get_pixmap(dpi=300).height], p.get_pixmap(dpi=300).samples), 'page': i+1} for i, p in enumerate(doc)]

    def _handle_image(self, path):
        img = Image.open(path).convert('RGB')
        img.thumbnail((2480, 2480), Image.LANCZOS)
        return [{'image': img, 'page': 1}]

    def _handle_txt(self, path):
        with open(path, 'r', encoding='utf-8') as f:
            text = f.read()
        return self._text_to_images(text)

    def _handle_docx(self, path):
        from docx import Document
        doc = Document(path)
        text = '\n'.join([p.text for p in doc.paragraphs])
        images = self._text_to_images(text)
        images += self.extract_docx_images(doc)
        return images

    def _text_to_images(self, text, width=2480, height=3508, font_size=24, max_lines=120):
        lines = text.split('\n')
        pages = []
        for i in range(0, len(lines), max_lines):
            img = Image.new("RGB", (width, height), "white")
            draw = ImageDraw.Draw(img)
            margin, offset = 50, 50
            for line in lines[i:i + max_lines]:
                draw.text((margin, offset), line, font=self.font, fill="black")
                offset += font_size + 10
                if offset > height - margin:
                    break
            pages.append({'image': img, 'page': (i // max_lines) + 1})
        return pages

    def extract_docx_images(self, doc):
        images = []
        for rel in doc.part.rels.values():
            if "image" in rel.target_ref:
                img = Image.open(io.BytesIO(rel.target_part.blob)).convert('RGB')
                images.append({'image': img, 'page': 'embedded'})
        return images

    def _to_gray(self, pil_img):
        img = np.array(pil_img)
        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) if len(img.shape) == 3 else img

    def enhance_contrast(self, pil_img, clip_limit=3.0, tile_grid_size=(8,8)):
        img = self._to_gray(pil_img)
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        return Image.fromarray(clahe.apply(img))

    def denoise(self, pil_img, h=15):
        img = self._to_gray(pil_img)
        return Image.fromarray(cv2.fastNlMeansDenoising(img, None, h, 7, 21))

    def sauvola_binarization(self, pil_img, window_size=35, k=0.2):
        gray = self._to_gray(pil_img)
        thresh = threshold_sauvola(gray, window_size=window_size, k=k)
        return Image.fromarray(((gray > thresh).astype(np.uint8) * 255))

    def otsu_binarization(self, pil_img):
        img = self._to_gray(pil_img)
        _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        return Image.fromarray(binary)

    def remove_lines(self, pil_img, horz_len=40, vert_len=40):
        img = self._to_gray(pil_img)
        _, binary = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
        horz_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (horz_len, 1))
        vert_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vert_len))
        lines = cv2.bitwise_or(
            cv2.morphologyEx(binary, cv2.MORPH_OPEN, horz_kernel, iterations=1),
            cv2.morphologyEx(binary, cv2.MORPH_OPEN, vert_kernel, iterations=1)
        )
        cleaned = cv2.bitwise_and(binary, cv2.bitwise_not(lines))
        return Image.fromarray(cleaned)

    def correct_skew(self, pil_img):
        img = self._to_gray(pil_img)
        angle = determine_skew(img)
        if abs(angle) > 0.1:
            (h, w) = img.shape
            M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)
            rotated = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
            return Image.fromarray(rotated)
        return pil_img

    def invert_image(self, pil_img):
        return Image.fromarray(255 - np.array(pil_img))

    def compute_quality_metrics(self, pil_img):
        img = np.array(pil_img)
        return {"mean": np.mean(img), "std": np.std(img), "contrast": img.max() - img.min()}

    def auto_select_binarization(self, metrics):
        return "otsu" if metrics["std"] < 50 and metrics["contrast"] > 100 else "sauvola"

    def auto_invert(self, pil_img):
        return np.mean(np.array(pil_img.convert('L'))) < 128

    def extract_layout_regions(self, pil_img):
        inputs = self.layout_processor(images=pil_img, return_tensors="pt")
        with torch.no_grad():
            outputs = self.layout_model(**inputs)
        target_sizes = torch.tensor([pil_img.size[::-1]])
        results = self.layout_processor.post_process_object_detection(
            outputs, threshold=0.5, target_sizes=target_sizes
        )[0]
        regions = []
        for box, label in zip(results["boxes"], results["labels"]):
            if label in [5, 8, 9]:  # Table, text, title
                xmin, ymin, xmax, ymax = map(int, box.tolist())
                regions.append((xmin, ymin, xmax, ymax, int(label)))
        return regions

    def crop_and_merge_regions(self, pil_img, regions):
        crops = [pil_img.crop((xmin, ymin, xmax, ymax)) for (xmin, ymin, xmax, ymax, _) in regions]
        if not crops:
            return pil_img
        widths, heights = zip(*(c.size for c in crops))
        merged = Image.new("RGB", (max(widths), sum(heights)), "white")
        y_offset = 0
        for c in crops:
            merged.paste(c, (0, y_offset))
            y_offset += c.size[1]
        return merged

    def process_single_page(
        self, img_dict,
        window_size=51, k=0.15,
        force_binarization=None,
        ocr_engine=None
    ):
        try:
            img = img_dict['image']
            page = img_dict['page']
            # Step 1: Denoise
            denoised = self.denoise(img)
            # Step 2: Enhance contrast (CLAHE)
            enhanced = self.enhance_contrast(denoised)
            # Step 3: Compute metrics
            metrics = self.compute_quality_metrics(enhanced)

            # Step 4: Decide on binarization method
            if force_binarization == "none":
                processed = enhanced
                bin_method = "none"
            elif force_binarization == "otsu":
                processed = self.otsu_binarization(enhanced)
                bin_method = "otsu"
            elif force_binarization == "sauvola":
                processed = self.sauvola_binarization(enhanced, window_size=window_size, k=k)
                bin_method = "sauvola"
            else:
                # Auto mode
                if metrics["contrast"] > 140 and metrics["std"] > 35:
                    processed = enhanced  # Use grayscale for OCR
                    bin_method = "none"
                else:
                    processed = self.sauvola_binarization(enhanced, window_size=window_size, k=k)
                    bin_method = "sauvola"

            # Step 5: Remove lines
            no_lines = self.remove_lines(processed)
            # Step 6: Deskew
            deskewed = self.correct_skew(no_lines)
            # Step 7: Invert if needed
            invert = self.auto_invert(deskewed)
            if invert:
                deskewed = self.invert_image(deskewed)
            # Step 8: Layout detection (DETR)
            regions = self.extract_layout_regions(deskewed.convert("RGB"))
            focused = self.crop_and_merge_regions(deskewed.convert("RGB"), regions)
            final_metrics = self.compute_quality_metrics(focused)

            # Step 9: OCR on both grayscale and binarized (if engine provided)
            ocr_results = {}
            if ocr_engine is not None:
                # Run OCR on both grayscale and binarized (if different)
                ocr_results["grayscale"] = ocr_engine(enhanced)
                if bin_method != "none":
                    ocr_results["binarized"] = ocr_engine(processed)
                else:
                    ocr_results["binarized"] = ocr_results["grayscale"]  # fallback

            return {
                "image": focused,
                "page": page,
                "metrics": final_metrics,
                "binarization": bin_method,
                "inverted": invert,
                "regions": regions,
                "ocr_results": ocr_results if ocr_results else None
            }
        except Exception as e:
            return {"image": None, "page": img_dict.get('page', '?'), "metrics": {}, "error": str(e)}

    def preprocess(
        self, input_path,
        window_size=51, k=0.15,
        force_binarization=None,
        ocr_engine=None
    ):
        images = self.normalize_document(input_path)
        with concurrent.futures.ThreadPoolExecutor(max_workers=min(4, len(images))) as executor:
            results = list(
                executor.map(
                    lambda img_dict: self.process_single_page(
                        img_dict,
                        window_size=window_size,
                        k=k,
                        force_binarization=force_binarization,
                        ocr_engine=ocr_engine
                    ),
                    images
                )
            )
        results.sort(key=lambda x: (str(x['page'])))
        return results

